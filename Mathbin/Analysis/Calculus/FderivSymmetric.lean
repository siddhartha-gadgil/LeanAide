/-
Copyright (c) 2021 SÃ©bastien GouÃ«zel. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: SÃ©bastien GouÃ«zel
-/
import Mathbin.Analysis.Calculus.Deriv
import Mathbin.Analysis.Calculus.MeanValue
import Mathbin.Analysis.Convex.Topology

/-!
# Symmetry of the second derivative

We show that, over the reals, the second derivative is symmetric.

The most precise result is `convex.second_derivative_within_at_symmetric`. It asserts that,
if a function is differentiable inside a convex set `s` with nonempty interior, and has a second
derivative within `s` at a point `x`, then this second derivative at `x` is symmetric. Note that
this result does not require continuity of the first derivative.

The following particular cases of this statement are especially relevant:

`second_derivative_symmetric_of_eventually` asserts that, if a function is differentiable on a
neighborhood of `x`, and has a second derivative at `x`, then this second derivative is symmetric.

`second_derivative_symmetric` asserts that, if a function is differentiable, and has a second
derivative at `x`, then this second derivative is symmetric.

## Implementation note

For the proof, we obtain an asymptotic expansion to order two of `f (x + v + w) - f (x + v)`, by
using the mean value inequality applied to a suitable function along the
segment `[x + v, x + v + w]`. This expansion involves `f'' â¬ w` as we move along a segment directed
by `w` (see `convex.taylor_approx_two_segment`).

Consider the alternate sum `f (x + v + w) + f x - f (x + v) - f (x + w)`, corresponding to the
values of `f` along a rectangle based at `x` with sides `v` and `w`. One can write it using the two
sides directed by `w`, as `(f (x + v + w) - f (x + v)) - (f (x + w) - f x)`. Together with the
previous asymptotic expansion, one deduces that it equals `f'' v w + o(1)` when `v, w` tends to `0`.
Exchanging the roles of `v` and `w`, one instead gets an asymptotic expansion `f'' w v`, from which
the equality `f'' v w = f'' w v` follows.

In our most general statement, we only assume that `f` is differentiable inside a convex set `s`, so
a few modifications have to be made. Since we don't assume continuity of `f` at `x`, we consider
instead the rectangle based at `x + v + w` with sides `v` and `w`,
in `convex.is_o_alternate_sum_square`, but the argument is essentially the same. It only works
when `v` and `w` both point towards the interior of `s`, to make sure that all the sides of the
rectangle are contained in `s` by convexity. The general case follows by linearity, though.
-/


open Asymptotics Set

open TopologicalSpace

variable {E F : Type _} [NormedGroup E] [NormedSpace â„ E] [NormedGroup F] [NormedSpace â„ F] {s : Set E}
  (s_conv : Convex â„ s) {f : E â†’ F} {f' : E â†’ E â†’L[â„] F} {f'' : E â†’L[â„] E â†’L[â„] F}
  (hf : âˆ€, âˆ€ x âˆˆ Interior s, âˆ€, HasFderivAt f (f' x) x) {x : E} (xs : x âˆˆ s)
  (hx : HasFderivWithinAt f' f'' (Interior s) x)

include s_conv xs hx hf

-- ./././Mathport/Syntax/Translate/Tactic/Basic.lean:63:9: parse error
-- ./././Mathport/Syntax/Translate/Tactic/Basic.lean:63:9: parse error
-- ./././Mathport/Syntax/Translate/Tactic/Basic.lean:63:9: parse error
-- ./././Mathport/Syntax/Translate/Tactic/Basic.lean:63:9: parse error
-- ./././Mathport/Syntax/Translate/Tactic/Basic.lean:63:9: parse error
/-- Assume that `f` is differentiable inside a convex set `s`, and that its derivative `f'` is
differentiable at a point `x`. Then, given two vectors `v` and `w` pointing inside `s`, one can
Taylor-expand to order two the function `f` on the segment `[x + h v, x + h (v + w)]`, giving a
bilinear estimate for `f (x + hv + hw) - f (x + hv)` in terms of `f' w` and of `f'' â¬ w`, up to
`o(h^2)`.

This is a technical statement used to show that the second derivative is symmetric.
-/
theorem Convex.taylor_approx_two_segment {v w : E} (hv : x + v âˆˆ Interior s) (hw : x + v + w âˆˆ Interior s) :
    (fun h : â„ =>
        f (x + h â€¢ v + h â€¢ w) - f (x + h â€¢ v) - h â€¢ f' x w - h ^ 2 â€¢ f'' v w - (h ^ 2 / 2) â€¢ f'' w w) =o[ğ“[>] 0]
      fun h => h ^ 2 :=
  by
  -- it suffices to check that the expression is bounded by `Îµ * ((âˆ¥vâˆ¥ + âˆ¥wâˆ¥) * âˆ¥wâˆ¥) * h^2` for
  -- small enough `h`, for any positive `Îµ`.
  apply is_o.trans_is_O (is_o_iff.2 fun Îµ Îµpos => _) (is_O_const_mul_self ((âˆ¥vâˆ¥ + âˆ¥wâˆ¥) * âˆ¥wâˆ¥) _ _)
  -- consider a ball of radius `Î´` around `x` in which the Taylor approximation for `f''` is
  -- good up to `Î´`.
  rw [HasFderivWithinAt, HasFderivAtFilter, is_o_iff] at hx
  rcases Metric.mem_nhds_within_iff.1 (hx Îµpos) with âŸ¨Î´, Î´pos, sÎ´âŸ©
  have E1 : âˆ€á¶  h in ğ“[>] (0 : â„), h * (âˆ¥vâˆ¥ + âˆ¥wâˆ¥) < Î´ := by
    have : Filter.Tendsto (fun h => h * (âˆ¥vâˆ¥ + âˆ¥wâˆ¥)) (ğ“[>] (0 : â„)) (ğ“ (0 * (âˆ¥vâˆ¥ + âˆ¥wâˆ¥))) :=
      (continuous_id.mul continuous_const).ContinuousWithinAt
    apply (tendsto_order.1 this).2 Î´
    simpa only [â† zero_mul] using Î´pos
  have E2 : âˆ€á¶  h in ğ“[>] (0 : â„), (h : â„) < 1 :=
    mem_nhds_within_Ioi_iff_exists_Ioo_subset.2
      âŸ¨(1 : â„), by
        simp only [â† mem_Ioi, â† zero_lt_one], fun x hx => hx.2âŸ©
  filter_upwards [E1, E2, self_mem_nhds_within] with h hÎ´ h_lt_1 hpos
  -- we consider `h` small enough that all points under consideration belong to this ball,
  -- and also with `0 < h < 1`.
  replace hpos : 0 < h := hpos
  have xt_mem : âˆ€, âˆ€ t âˆˆ Icc (0 : â„) 1, âˆ€, x + h â€¢ v + (t * h) â€¢ w âˆˆ Interior s := by
    intro t ht
    have : x + h â€¢ v âˆˆ Interior s := s_conv.add_smul_mem_interior xs hv âŸ¨hpos, h_lt_1.leâŸ©
    rw [â† smul_smul]
    apply s_conv.interior.add_smul_mem this _ ht
    rw [add_assocâ‚“] at hw
    rw [add_assocâ‚“, â† smul_add]
    exact s_conv.add_smul_mem_interior xs hw âŸ¨hpos, h_lt_1.leâŸ©
  -- define a function `g` on `[0,1]` (identified with `[v, v + w]`) such that `g 1 - g 0` is the
  -- quantity to be estimated. We will check that its derivative is given by an explicit
  -- expression `g'`, that we can bound. Then the desired bound for `g 1 - g 0` follows from the
  -- mean value inequality.
  let g := fun t => f (x + h â€¢ v + (t * h) â€¢ w) - (t * h) â€¢ f' x w - (t * h ^ 2) â€¢ f'' v w - ((t * h) ^ 2 / 2) â€¢ f'' w w
  set g' := fun t => f' (x + h â€¢ v + (t * h) â€¢ w) (h â€¢ w) - h â€¢ f' x w - h ^ 2 â€¢ f'' v w - (t * h ^ 2) â€¢ f'' w w with
    hg'
  -- check that `g'` is the derivative of `g`, by a straightforward computation
  have g_deriv : âˆ€, âˆ€ t âˆˆ Icc (0 : â„) 1, âˆ€, HasDerivWithinAt g (g' t) (Icc 0 1) t := by
    intro t ht
    apply_rules [HasDerivWithinAt.sub, HasDerivWithinAt.add]
    Â· refine' (hf _ _).comp_has_deriv_within_at _ _
      Â· exact xt_mem t ht
        
      apply_rules [HasDerivAt.has_deriv_within_at, HasDerivAt.const_add, HasDerivAt.smul_const, has_deriv_at_mul_const]
      
    Â· apply_rules [HasDerivAt.has_deriv_within_at, HasDerivAt.smul_const, has_deriv_at_mul_const]
      
    Â· apply_rules [HasDerivAt.has_deriv_within_at, HasDerivAt.smul_const, has_deriv_at_mul_const]
      
    Â· suffices H :
        HasDerivWithinAt (fun u => ((u * h) ^ 2 / 2) â€¢ f'' w w)
          ((((2 : â„•) : â„) * (t * h) ^ (2 - 1) * (1 * h) / 2) â€¢ f'' w w) (Icc 0 1) t
      Â· convert H using 2
        simp only [â† one_mulâ‚“, â† Nat.cast_bit0, â† pow_oneâ‚“, â† Nat.cast_oneâ‚“]
        ring
        
      apply_rules [HasDerivAt.has_deriv_within_at, HasDerivAt.smul_const, has_deriv_at_id', HasDerivAt.pow,
        HasDerivAt.mul_const]
      
  -- check that `g'` is uniformly bounded, with a suitable bound `Îµ * ((âˆ¥vâˆ¥ + âˆ¥wâˆ¥) * âˆ¥wâˆ¥) * h^2`.
  have g'_bound : âˆ€, âˆ€ t âˆˆ Ico (0 : â„) 1, âˆ€, âˆ¥g' tâˆ¥ â‰¤ Îµ * ((âˆ¥vâˆ¥ + âˆ¥wâˆ¥) * âˆ¥wâˆ¥) * h ^ 2 := by
    intro t ht
    have I : âˆ¥h â€¢ v + (t * h) â€¢ wâˆ¥ â‰¤ h * (âˆ¥vâˆ¥ + âˆ¥wâˆ¥) :=
      calc
        âˆ¥h â€¢ v + (t * h) â€¢ wâˆ¥ â‰¤ âˆ¥h â€¢ vâˆ¥ + âˆ¥(t * h) â€¢ wâˆ¥ := norm_add_le _ _
        _ = h * âˆ¥vâˆ¥ + t * (h * âˆ¥wâˆ¥) := by
          simp only [â† norm_smul, â† Real.norm_eq_abs, â† hpos.le, â† abs_of_nonneg, â† abs_mul, â† ht.left, â† mul_assoc]
        _ â‰¤ h * âˆ¥vâˆ¥ + 1 * (h * âˆ¥wâˆ¥) :=
          add_le_add le_rfl (mul_le_mul_of_nonneg_right ht.2.le (mul_nonneg hpos.le (norm_nonneg _)))
        _ = h * (âˆ¥vâˆ¥ + âˆ¥wâˆ¥) := by
          ring
        
    calc âˆ¥g' tâˆ¥ = âˆ¥(f' (x + h â€¢ v + (t * h) â€¢ w) - f' x - f'' (h â€¢ v + (t * h) â€¢ w)) (h â€¢ w)âˆ¥ := by
        rw [hg']
        have : h * (t * h) = t * (h * h) := by
          ring
        simp only [â† ContinuousLinearMap.coe_sub', â† ContinuousLinearMap.map_add, â† pow_two, â†
          ContinuousLinearMap.add_apply, â† Pi.smul_apply, â† smul_sub, â† smul_add, â† smul_smul, sub_sub, â†
          ContinuousLinearMap.coe_smul', â† Pi.sub_apply, â† ContinuousLinearMap.map_smul, â†
          this]_ â‰¤ âˆ¥f' (x + h â€¢ v + (t * h) â€¢ w) - f' x - f'' (h â€¢ v + (t * h) â€¢ w)âˆ¥ * âˆ¥h â€¢ wâˆ¥ :=
        ContinuousLinearMap.le_op_norm _ _ _ â‰¤ Îµ * âˆ¥h â€¢ v + (t * h) â€¢ wâˆ¥ * âˆ¥h â€¢ wâˆ¥ := by
        apply mul_le_mul_of_nonneg_right _ (norm_nonneg _)
        have H : x + h â€¢ v + (t * h) â€¢ w âˆˆ Metric.Ball x Î´ âˆ© Interior s := by
          refine' âŸ¨_, xt_mem t âŸ¨ht.1, ht.2.leâŸ©âŸ©
          rw [add_assocâ‚“, add_mem_ball_iff_norm]
          exact I.trans_lt hÎ´
        simpa only [â† mem_set_of_eq, â† add_assocâ‚“ x, â† add_sub_cancel'] using
          sÎ´ H _ â‰¤ Îµ * (âˆ¥h â€¢ vâˆ¥ + âˆ¥h â€¢ wâˆ¥) * âˆ¥h â€¢ wâˆ¥ :=
        by
        apply mul_le_mul_of_nonneg_right _ (norm_nonneg _)
        apply mul_le_mul_of_nonneg_left _ Îµpos.le
        apply (norm_add_le _ _).trans
        refine' add_le_add le_rfl _
        simp only [â† norm_smul, â† Real.norm_eq_abs, â† abs_mul, â† abs_of_nonneg, â† ht.1, â† hpos.le, â† mul_assoc]
        exact mul_le_of_le_one_left (mul_nonneg hpos.le (norm_nonneg _)) ht.2.le _ = Îµ * ((âˆ¥vâˆ¥ + âˆ¥wâˆ¥) * âˆ¥wâˆ¥) * h ^ 2 :=
        by
        simp only [â† norm_smul, â† Real.norm_eq_abs, â† abs_mul, â† abs_of_nonneg, â† hpos.le]
        ring
  -- conclude using the mean value inequality
  have I : âˆ¥g 1 - g 0âˆ¥ â‰¤ Îµ * ((âˆ¥vâˆ¥ + âˆ¥wâˆ¥) * âˆ¥wâˆ¥) * h ^ 2 := by
    simpa only [â† mul_oneâ‚“, â† sub_zero] using
      norm_image_sub_le_of_norm_deriv_le_segment' g_deriv g'_bound 1 (right_mem_Icc.2 zero_le_one)
  convert I using 1
  Â· congr 1
    dsimp' only [â† g]
    simp only [â† Nat.one_ne_zero, â† add_zeroâ‚“, â† one_mulâ‚“, â† zero_div, â† zero_mul, â† sub_zero, â† zero_smul, â† Ne.def, â†
      not_false_iff, â† bit0_eq_zero, â† zero_pow']
    abel
    
  Â· simp only [â† Real.norm_eq_abs, â† abs_mul, â† add_nonneg (norm_nonneg v) (norm_nonneg w), â† abs_of_nonneg, â†
      mul_assoc, â† pow_bit0_abs, â† norm_nonneg, â† abs_pow]
    

/-- One can get `f'' v w` as the limit of `h ^ (-2)` times the alternate sum of the values of `f`
along the vertices of a quadrilateral with sides `h v` and `h w` based at `x`.
In a setting where `f` is not guaranteed to be continuous at `f`, we can still
get this if we use a quadrilateral based at `h v + h w`. -/
theorem Convex.is_o_alternate_sum_square {v w : E} (h4v : x + (4 : â„) â€¢ v âˆˆ Interior s)
    (h4w : x + (4 : â„) â€¢ w âˆˆ Interior s) :
    (fun h : â„ =>
        f (x + h â€¢ (2 â€¢ v + 2 â€¢ w)) + f (x + h â€¢ (v + w)) - f (x + h â€¢ (2 â€¢ v + w)) - f (x + h â€¢ (v + 2 â€¢ w)) -
          h ^ 2 â€¢ f'' v w) =o[ğ“[>] 0]
      fun h => h ^ 2 :=
  by
  have A : (1 : â„) / 2 âˆˆ Ioc (0 : â„) 1 :=
    âŸ¨by
      norm_num, by
      norm_numâŸ©
  have B : (1 : â„) / 2 âˆˆ Icc (0 : â„) 1 :=
    âŸ¨by
      norm_num, by
      norm_numâŸ©
  have C : âˆ€ w : E, (2 : â„) â€¢ w = 2 â€¢ w := fun w => by
    simp only [â† two_smul]
  have h2v2w : x + (2 : â„) â€¢ v + (2 : â„) â€¢ w âˆˆ Interior s := by
    convert s_conv.interior.add_smul_sub_mem h4v h4w B using 1
    simp only [â† smul_sub, â† smul_smul, â† one_div, â† add_sub_add_left_eq_sub, â† mul_addâ‚“, â† add_smul]
    norm_num
    simp only [â†
      show (4 : â„) = (2 : â„) + (2 : â„) by
        norm_num,
      â† add_smul]
    abel
  have h2vww : x + (2 â€¢ v + w) + w âˆˆ Interior s := by
    convert h2v2w using 1
    simp only [â† two_smul]
    abel
  have h2v : x + (2 : â„) â€¢ v âˆˆ Interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h4v A using 1
    simp only [â† smul_smul, â† one_div, â† add_sub_cancel', â† add_right_injâ‚“]
    norm_num
  have h2w : x + (2 : â„) â€¢ w âˆˆ Interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h4w A using 1
    simp only [â† smul_smul, â† one_div, â† add_sub_cancel', â† add_right_injâ‚“]
    norm_num
  have hvw : x + (v + w) âˆˆ Interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h2v2w A using 1
    simp only [â† smul_smul, â† one_div, â† add_sub_cancel', â† add_right_injâ‚“, â† smul_add, â† smul_sub]
    norm_num
    abel
  have h2vw : x + (2 â€¢ v + w) âˆˆ Interior s := by
    convert s_conv.interior.add_smul_sub_mem h2v h2v2w B using 1
    simp only [â† smul_add, â† smul_sub, â† smul_smul, C]
    norm_num
    abel
  have hvww : x + (v + w) + w âˆˆ Interior s := by
    convert s_conv.interior.add_smul_sub_mem h2w h2v2w B using 1
    simp only [â† one_div, â† add_sub_cancel', â† inv_smul_smulâ‚€, â† add_sub_add_right_eq_sub, â† Ne.def, â† not_false_iff, â†
      bit0_eq_zero, â† one_ne_zero]
    rw [two_smul]
    abel
  have TA1 := s_conv.taylor_approx_two_segment hf xs hx h2vw h2vww
  have TA2 := s_conv.taylor_approx_two_segment hf xs hx hvw hvww
  convert TA1.sub TA2
  ext h
  simp only [â† two_smul, â† smul_add, add_assocâ‚“, â† ContinuousLinearMap.map_add, â† ContinuousLinearMap.add_apply, â†
    Pi.smul_apply, â† ContinuousLinearMap.coe_smul', â† ContinuousLinearMap.map_smul]
  abel

/-- Assume that `f` is differentiable inside a convex set `s`, and that its derivative `f'` is
differentiable at a point `x`. Then, given two vectors `v` and `w` pointing inside `s`, one
has `f'' v w = f'' w v`. Superseded by `convex.second_derivative_within_at_symmetric`, which
removes the assumption that `v` and `w` point inside `s`.
-/
theorem Convex.second_derivative_within_at_symmetric_of_mem_interior {v w : E} (h4v : x + (4 : â„) â€¢ v âˆˆ Interior s)
    (h4w : x + (4 : â„) â€¢ w âˆˆ Interior s) : f'' w v = f'' v w := by
  have A : (fun h : â„ => h ^ 2 â€¢ (f'' w v - f'' v w)) =o[ğ“[>] 0] fun h => h ^ 2 := by
    convert (s_conv.is_o_alternate_sum_square hf xs hx h4v h4w).sub (s_conv.is_o_alternate_sum_square hf xs hx h4w h4v)
    ext h
    simp only [â† add_commâ‚“, â† smul_add, â† smul_sub]
    abel
  have B : (fun h : â„ => f'' w v - f'' v w) =o[ğ“[>] 0] fun h => (1 : â„) := by
    have : (fun h : â„ => 1 / h ^ 2) =O[ğ“[>] 0] fun h => 1 / h ^ 2 := is_O_refl _ _
    have C := this.smul_is_o A
    apply C.congr' _ _
    Â· filter_upwards [self_mem_nhds_within]
      intro h hpos
      rw [â† one_smul â„ (f'' w v - f'' v w), smul_smul, smul_smul]
      congr 1
      field_simp [â† LT.lt.ne' hpos]
      
    Â· filter_upwards [self_mem_nhds_within] with _ hpos
      field_simp [â† LT.lt.ne' hpos, â† HasSmul.smul]
      
  simpa only [â† sub_eq_zero] using is_o_const_const_iff.1 B

omit s_conv xs hx hf

/-- If a function is differentiable inside a convex set with nonempty interior, and has a second
derivative at a point of this convex set, then this second derivative is symmetric. -/
theorem Convex.second_derivative_within_at_symmetric {s : Set E} (s_conv : Convex â„ s) (hne : (Interior s).Nonempty)
    {f : E â†’ F} {f' : E â†’ E â†’L[â„] F} {f'' : E â†’L[â„] E â†’L[â„] F} (hf : âˆ€, âˆ€ x âˆˆ Interior s, âˆ€, HasFderivAt f (f' x) x)
    {x : E} (xs : x âˆˆ s) (hx : HasFderivWithinAt f' f'' (Interior s) x) (v w : E) : f'' v w = f'' w v := by
  /- we work around a point `x + 4 z` in the interior of `s`. For any vector `m`,
    then `x + 4 (z + t m)` also belongs to the interior of `s` for small enough `t`. This means that
    we will be able to apply `second_derivative_within_at_symmetric_of_mem_interior` to show
    that `f''` is symmetric, after cancelling all the contributions due to `z`. -/
  rcases hne with âŸ¨y, hyâŸ©
  obtain âŸ¨z, hzâŸ© : âˆƒ z, z = ((1 : â„) / 4) â€¢ (y - x) := âŸ¨((1 : â„) / 4) â€¢ (y - x), rflâŸ©
  have A : âˆ€ m : E, Filter.Tendsto (fun t : â„ => x + (4 : â„) â€¢ (z + t â€¢ m)) (ğ“ 0) (ğ“ y) := by
    intro m
    have : x + (4 : â„) â€¢ (z + (0 : â„) â€¢ m) = y := by
      simp [â† hz]
    rw [â† this]
    refine' tendsto_const_nhds.add _
    refine' tendsto_const_nhds.smul _
    refine' tendsto_const_nhds.add _
    exact continuous_at_id.smul continuous_at_const
  have B : âˆ€ m : E, âˆ€á¶  t in ğ“[>] (0 : â„), x + (4 : â„) â€¢ (z + t â€¢ m) âˆˆ Interior s := by
    intro m
    apply nhds_within_le_nhds
    apply A m
    rw [mem_interior_iff_mem_nhds] at hy
    exact interior_mem_nhds.2 hy
  -- we choose `t m > 0` such that `x + 4 (z + (t m) m)` belongs to the interior of `s`, for any
  -- vector `m`.
  choose t ts tpos using fun m => ((B m).And self_mem_nhds_within).exists
  -- applying `second_derivative_within_at_symmetric_of_mem_interior` to the vectors `z`
  -- and `z + (t m) m`, we deduce that `f'' m z = f'' z m` for all `m`.
  have C : âˆ€ m : E, f'' m z = f'' z m := by
    intro m
    have : f'' (z + t m â€¢ m) (z + t 0 â€¢ 0) = f'' (z + t 0 â€¢ 0) (z + t m â€¢ m) :=
      s_conv.second_derivative_within_at_symmetric_of_mem_interior hf xs hx (ts 0) (ts m)
    simp only [â† ContinuousLinearMap.map_add, â† ContinuousLinearMap.map_smul, â† add_right_injâ‚“, â†
      ContinuousLinearMap.add_apply, â† Pi.smul_apply, â† ContinuousLinearMap.coe_smul', â† add_zeroâ‚“, â†
      ContinuousLinearMap.zero_apply, â† smul_zero, â† ContinuousLinearMap.map_zero] at this
    exact smul_right_injective F (tpos m).ne' this
  -- applying `second_derivative_within_at_symmetric_of_mem_interior` to the vectors `z + (t v) v`
  -- and `z + (t w) w`, we deduce that `f'' v w = f'' w v`. Cross terms involving `z` can be
  -- eliminated thanks to the fact proved above that `f'' m z = f'' z m`.
  have : f'' (z + t v â€¢ v) (z + t w â€¢ w) = f'' (z + t w â€¢ w) (z + t v â€¢ v) :=
    s_conv.second_derivative_within_at_symmetric_of_mem_interior hf xs hx (ts w) (ts v)
  simp only [â† ContinuousLinearMap.map_add, â† ContinuousLinearMap.map_smul, â† smul_add, â† smul_smul, â†
    ContinuousLinearMap.add_apply, â† Pi.smul_apply, â† ContinuousLinearMap.coe_smul', â† C] at this
  rw [â† sub_eq_zero] at this
  abel  at this
  simp only [â† one_zsmul, â† neg_smul, â† sub_eq_zero, â† mul_comm, sub_eq_add_neg] at this
  apply smul_right_injective F _ this
  simp [â† (tpos v).ne', â† (tpos w).ne']

/-- If a function is differentiable around `x`, and has two derivatives at `x`, then the second
derivative is symmetric. -/
theorem second_derivative_symmetric_of_eventually {f : E â†’ F} {f' : E â†’ E â†’L[â„] F} {f'' : E â†’L[â„] E â†’L[â„] F}
    (hf : âˆ€á¶  y in ğ“ x, HasFderivAt f (f' y) y) (hx : HasFderivAt f' f'' x) (v w : E) : f'' v w = f'' w v := by
  rcases Metric.mem_nhds_iff.1 hf with âŸ¨Îµ, Îµpos, hÎµâŸ©
  have A : (Interior (Metric.Ball x Îµ)).Nonempty := by
    rwa [metric.is_open_ball.interior_eq, Metric.nonempty_ball]
  exact
    Convex.second_derivative_within_at_symmetric (convex_ball x Îµ) A (fun y hy => hÎµ (interior_subset hy))
      (Metric.mem_ball_self Îµpos) hx.has_fderiv_within_at v w

/-- If a function is differentiable, and has two derivatives at `x`, then the second
derivative is symmetric. -/
theorem second_derivative_symmetric {f : E â†’ F} {f' : E â†’ E â†’L[â„] F} {f'' : E â†’L[â„] E â†’L[â„] F}
    (hf : âˆ€ y, HasFderivAt f (f' y) y) (hx : HasFderivAt f' f'' x) (v w : E) : f'' v w = f'' w v :=
  second_derivative_symmetric_of_eventually (Filter.eventually_of_forall hf) hx v w

